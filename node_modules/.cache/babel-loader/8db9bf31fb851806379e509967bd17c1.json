{"ast":null,"code":"/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Functions that generate fragmented MP4s suitable for use with Media\n * Source Extensions.\n */\n'use strict';\n\nvar UINT32_MAX = Math.pow(2, 32) - 1;\nvar box, dinf, esds, ftyp, mdat, mfhd, minf, moof, moov, mvex, mvhd, trak, tkhd, mdia, mdhd, hdlr, sdtp, stbl, stsd, traf, trex, trun, types, MAJOR_BRAND, MINOR_VERSION, AVC1_BRAND, VIDEO_HDLR, AUDIO_HDLR, HDLR_TYPES, VMHD, SMHD, DREF, STCO, STSC, STSZ, STTS; // pre-calculate constants\n\n(function () {\n  var i;\n  types = {\n    avc1: [],\n    // codingname\n    avcC: [],\n    btrt: [],\n    dinf: [],\n    dref: [],\n    esds: [],\n    ftyp: [],\n    hdlr: [],\n    mdat: [],\n    mdhd: [],\n    mdia: [],\n    mfhd: [],\n    minf: [],\n    moof: [],\n    moov: [],\n    mp4a: [],\n    // codingname\n    mvex: [],\n    mvhd: [],\n    sdtp: [],\n    smhd: [],\n    stbl: [],\n    stco: [],\n    stsc: [],\n    stsd: [],\n    stsz: [],\n    stts: [],\n    styp: [],\n    tfdt: [],\n    tfhd: [],\n    traf: [],\n    trak: [],\n    trun: [],\n    trex: [],\n    tkhd: [],\n    vmhd: []\n  }; // In environments where Uint8Array is undefined (e.g., IE8), skip set up so that we\n  // don't throw an error\n\n  if (typeof Uint8Array === 'undefined') {\n    return;\n  }\n\n  for (i in types) {\n    if (types.hasOwnProperty(i)) {\n      types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\n    }\n  }\n\n  MAJOR_BRAND = new Uint8Array(['i'.charCodeAt(0), 's'.charCodeAt(0), 'o'.charCodeAt(0), 'm'.charCodeAt(0)]);\n  AVC1_BRAND = new Uint8Array(['a'.charCodeAt(0), 'v'.charCodeAt(0), 'c'.charCodeAt(0), '1'.charCodeAt(0)]);\n  MINOR_VERSION = new Uint8Array([0, 0, 0, 1]);\n  VIDEO_HDLR = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x00, // pre_defined\n  0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n  ]);\n  AUDIO_HDLR = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x00, // pre_defined\n  0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n  ]);\n  HDLR_TYPES = {\n    video: VIDEO_HDLR,\n    audio: AUDIO_HDLR\n  };\n  DREF = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x01, // entry_count\n  0x00, 0x00, 0x00, 0x0c, // entry_size\n  0x75, 0x72, 0x6c, 0x20, // 'url' type\n  0x00, // version 0\n  0x00, 0x00, 0x01 // entry_flags\n  ]);\n  SMHD = new Uint8Array([0x00, // version\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, // balance, 0 means centered\n  0x00, 0x00 // reserved\n  ]);\n  STCO = new Uint8Array([0x00, // version\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x00 // entry_count\n  ]);\n  STSC = STCO;\n  STSZ = new Uint8Array([0x00, // version\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x00, // sample_size\n  0x00, 0x00, 0x00, 0x00 // sample_count\n  ]);\n  STTS = STCO;\n  VMHD = new Uint8Array([0x00, // version\n  0x00, 0x00, 0x01, // flags\n  0x00, 0x00, // graphicsmode\n  0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n  ]);\n})();\n\nbox = function box(type) {\n  var payload = [],\n      size = 0,\n      i,\n      result,\n      view;\n\n  for (i = 1; i < arguments.length; i++) {\n    payload.push(arguments[i]);\n  }\n\n  i = payload.length; // calculate the total size we need to allocate\n\n  while (i--) {\n    size += payload[i].byteLength;\n  }\n\n  result = new Uint8Array(size + 8);\n  view = new DataView(result.buffer, result.byteOffset, result.byteLength);\n  view.setUint32(0, result.byteLength);\n  result.set(type, 4); // copy the payload into the result\n\n  for (i = 0, size = 8; i < payload.length; i++) {\n    result.set(payload[i], size);\n    size += payload[i].byteLength;\n  }\n\n  return result;\n};\n\ndinf = function dinf() {\n  return box(types.dinf, box(types.dref, DREF));\n};\n\nesds = function esds(track) {\n  return box(types.esds, new Uint8Array([0x00, // version\n  0x00, 0x00, 0x00, // flags\n  // ES_Descriptor\n  0x03, // tag, ES_DescrTag\n  0x19, // length\n  0x00, 0x00, // ES_ID\n  0x00, // streamDependenceFlag, URL_flag, reserved, streamPriority\n  // DecoderConfigDescriptor\n  0x04, // tag, DecoderConfigDescrTag\n  0x11, // length\n  0x40, // object type\n  0x15, // streamType\n  0x00, 0x06, 0x00, // bufferSizeDB\n  0x00, 0x00, 0xda, 0xc0, // maxBitrate\n  0x00, 0x00, 0xda, 0xc0, // avgBitrate\n  // DecoderSpecificInfo\n  0x05, // tag, DecoderSpecificInfoTag\n  0x02, // length\n  // ISO/IEC 14496-3, AudioSpecificConfig\n  // for samplingFrequencyIndex see ISO/IEC 13818-7:2006, 8.1.3.2.2, Table 35\n  track.audioobjecttype << 3 | track.samplingfrequencyindex >>> 1, track.samplingfrequencyindex << 7 | track.channelcount << 3, 0x06, 0x01, 0x02 // GASpecificConfig\n  ]));\n};\n\nftyp = function ftyp() {\n  return box(types.ftyp, MAJOR_BRAND, MINOR_VERSION, MAJOR_BRAND, AVC1_BRAND);\n};\n\nhdlr = function hdlr(type) {\n  return box(types.hdlr, HDLR_TYPES[type]);\n};\n\nmdat = function mdat(data) {\n  return box(types.mdat, data);\n};\n\nmdhd = function mdhd(track) {\n  var result = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x02, // creation_time\n  0x00, 0x00, 0x00, 0x03, // modification_time\n  0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n  track.duration >>> 24 & 0xFF, track.duration >>> 16 & 0xFF, track.duration >>> 8 & 0xFF, track.duration & 0xFF, // duration\n  0x55, 0xc4, // 'und' language (undetermined)\n  0x00, 0x00]); // Use the sample rate from the track metadata, when it is\n  // defined. The sample rate can be parsed out of an ADTS header, for\n  // instance.\n\n  if (track.samplerate) {\n    result[12] = track.samplerate >>> 24 & 0xFF;\n    result[13] = track.samplerate >>> 16 & 0xFF;\n    result[14] = track.samplerate >>> 8 & 0xFF;\n    result[15] = track.samplerate & 0xFF;\n  }\n\n  return box(types.mdhd, result);\n};\n\nmdia = function mdia(track) {\n  return box(types.mdia, mdhd(track), hdlr(track.type), minf(track));\n};\n\nmfhd = function mfhd(sequenceNumber) {\n  return box(types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // flags\n  (sequenceNumber & 0xFF000000) >> 24, (sequenceNumber & 0xFF0000) >> 16, (sequenceNumber & 0xFF00) >> 8, sequenceNumber & 0xFF // sequence_number\n  ]));\n};\n\nminf = function minf(track) {\n  return box(types.minf, track.type === 'video' ? box(types.vmhd, VMHD) : box(types.smhd, SMHD), dinf(), stbl(track));\n};\n\nmoof = function moof(sequenceNumber, tracks) {\n  var trackFragments = [],\n      i = tracks.length; // build traf boxes for each track fragment\n\n  while (i--) {\n    trackFragments[i] = traf(tracks[i]);\n  }\n\n  return box.apply(null, [types.moof, mfhd(sequenceNumber)].concat(trackFragments));\n};\n/**\n * Returns a movie box.\n * @param tracks {array} the tracks associated with this movie\n * @see ISO/IEC 14496-12:2012(E), section 8.2.1\n */\n\n\nmoov = function moov(tracks) {\n  var i = tracks.length,\n      boxes = [];\n\n  while (i--) {\n    boxes[i] = trak(tracks[i]);\n  }\n\n  return box.apply(null, [types.moov, mvhd(0xffffffff)].concat(boxes).concat(mvex(tracks)));\n};\n\nmvex = function mvex(tracks) {\n  var i = tracks.length,\n      boxes = [];\n\n  while (i--) {\n    boxes[i] = trex(tracks[i]);\n  }\n\n  return box.apply(null, [types.mvex].concat(boxes));\n};\n\nmvhd = function mvhd(duration) {\n  var bytes = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x00, // flags\n  0x00, 0x00, 0x00, 0x01, // creation_time\n  0x00, 0x00, 0x00, 0x02, // modification_time\n  0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n  (duration & 0xFF000000) >> 24, (duration & 0xFF0000) >> 16, (duration & 0xFF00) >> 8, duration & 0xFF, // duration\n  0x00, 0x01, 0x00, 0x00, // 1.0 rate\n  0x01, 0x00, // 1.0 volume\n  0x00, 0x00, // reserved\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n  0xff, 0xff, 0xff, 0xff // next_track_ID\n  ]);\n  return box(types.mvhd, bytes);\n};\n\nsdtp = function sdtp(track) {\n  var samples = track.samples || [],\n      bytes = new Uint8Array(4 + samples.length),\n      flags,\n      i; // leave the full box header (4 bytes) all zero\n  // write the sample table\n\n  for (i = 0; i < samples.length; i++) {\n    flags = samples[i].flags;\n    bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\n  }\n\n  return box(types.sdtp, bytes);\n};\n\nstbl = function stbl(track) {\n  return box(types.stbl, stsd(track), box(types.stts, STTS), box(types.stsc, STSC), box(types.stsz, STSZ), box(types.stco, STCO));\n};\n\n(function () {\n  var videoSample, audioSample;\n\n  stsd = function stsd(track) {\n    return box(types.stsd, new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01]), track.type === 'video' ? videoSample(track) : audioSample(track));\n  };\n\n  videoSample = function videoSample(track) {\n    var sps = track.sps || [],\n        pps = track.pps || [],\n        sequenceParameterSets = [],\n        pictureParameterSets = [],\n        i; // assemble the SPSs\n\n    for (i = 0; i < sps.length; i++) {\n      sequenceParameterSets.push((sps[i].byteLength & 0xFF00) >>> 8);\n      sequenceParameterSets.push(sps[i].byteLength & 0xFF); // sequenceParameterSetLength\n\n      sequenceParameterSets = sequenceParameterSets.concat(Array.prototype.slice.call(sps[i])); // SPS\n    } // assemble the PPSs\n\n\n    for (i = 0; i < pps.length; i++) {\n      pictureParameterSets.push((pps[i].byteLength & 0xFF00) >>> 8);\n      pictureParameterSets.push(pps[i].byteLength & 0xFF);\n      pictureParameterSets = pictureParameterSets.concat(Array.prototype.slice.call(pps[i]));\n    }\n\n    return box(types.avc1, new Uint8Array([0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    0x00, 0x00, // pre_defined\n    0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n    (track.width & 0xff00) >> 8, track.width & 0xff, // width\n    (track.height & 0xff00) >> 8, track.height & 0xff, // height\n    0x00, 0x48, 0x00, 0x00, // horizresolution\n    0x00, 0x48, 0x00, 0x00, // vertresolution\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // frame_count\n    0x13, 0x76, 0x69, 0x64, 0x65, 0x6f, 0x6a, 0x73, 0x2d, 0x63, 0x6f, 0x6e, 0x74, 0x72, 0x69, 0x62, 0x2d, 0x68, 0x6c, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // compressorname\n    0x00, 0x18, // depth = 24\n    0x11, 0x11 // pre_defined = -1\n    ]), box(types.avcC, new Uint8Array([0x01, // configurationVersion\n    track.profileIdc, // AVCProfileIndication\n    track.profileCompatibility, // profile_compatibility\n    track.levelIdc, // AVCLevelIndication\n    0xff // lengthSizeMinusOne, hard-coded to 4 bytes\n    ].concat([sps.length // numOfSequenceParameterSets\n    ]).concat(sequenceParameterSets).concat([pps.length // numOfPictureParameterSets\n    ]).concat(pictureParameterSets))), // \"PPS\"\n    box(types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\n    0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\n    0x00, 0x2d, 0xc6, 0xc0])) // avgBitrate\n    );\n  };\n\n  audioSample = function audioSample(track) {\n    return box(types.mp4a, new Uint8Array([// SampleEntry, ISO/IEC 14496-12\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    // AudioSampleEntry, ISO/IEC 14496-12\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    (track.channelcount & 0xff00) >> 8, track.channelcount & 0xff, // channelcount\n    (track.samplesize & 0xff00) >> 8, track.samplesize & 0xff, // samplesize\n    0x00, 0x00, // pre_defined\n    0x00, 0x00, // reserved\n    (track.samplerate & 0xff00) >> 8, track.samplerate & 0xff, 0x00, 0x00 // samplerate, 16.16\n    // MP4AudioSampleEntry, ISO/IEC 14496-14\n    ]), esds(track));\n  };\n})();\n\ntkhd = function tkhd(track) {\n  var result = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x07, // flags\n  0x00, 0x00, 0x00, 0x00, // creation_time\n  0x00, 0x00, 0x00, 0x00, // modification_time\n  (track.id & 0xFF000000) >> 24, (track.id & 0xFF0000) >> 16, (track.id & 0xFF00) >> 8, track.id & 0xFF, // track_ID\n  0x00, 0x00, 0x00, 0x00, // reserved\n  (track.duration & 0xFF000000) >> 24, (track.duration & 0xFF0000) >> 16, (track.duration & 0xFF00) >> 8, track.duration & 0xFF, // duration\n  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n  0x00, 0x00, // layer\n  0x00, 0x00, // alternate_group\n  0x01, 0x00, // non-audio track volume\n  0x00, 0x00, // reserved\n  0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n  (track.width & 0xFF00) >> 8, track.width & 0xFF, 0x00, 0x00, // width\n  (track.height & 0xFF00) >> 8, track.height & 0xFF, 0x00, 0x00 // height\n  ]);\n  return box(types.tkhd, result);\n};\n/**\n * Generate a track fragment (traf) box. A traf box collects metadata\n * about tracks in a movie fragment (moof) box.\n */\n\n\ntraf = function traf(track) {\n  var trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun, sampleDependencyTable, dataOffset, upperWordBaseMediaDecodeTime, lowerWordBaseMediaDecodeTime;\n  trackFragmentHeader = box(types.tfhd, new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x3a, // flags\n  (track.id & 0xFF000000) >> 24, (track.id & 0xFF0000) >> 16, (track.id & 0xFF00) >> 8, track.id & 0xFF, // track_ID\n  0x00, 0x00, 0x00, 0x01, // sample_description_index\n  0x00, 0x00, 0x00, 0x00, // default_sample_duration\n  0x00, 0x00, 0x00, 0x00, // default_sample_size\n  0x00, 0x00, 0x00, 0x00 // default_sample_flags\n  ]));\n  upperWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime / (UINT32_MAX + 1));\n  lowerWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime % (UINT32_MAX + 1));\n  trackFragmentDecodeTime = box(types.tfdt, new Uint8Array([0x01, // version 1\n  0x00, 0x00, 0x00, // flags\n  // baseMediaDecodeTime\n  upperWordBaseMediaDecodeTime >>> 24 & 0xFF, upperWordBaseMediaDecodeTime >>> 16 & 0xFF, upperWordBaseMediaDecodeTime >>> 8 & 0xFF, upperWordBaseMediaDecodeTime & 0xFF, lowerWordBaseMediaDecodeTime >>> 24 & 0xFF, lowerWordBaseMediaDecodeTime >>> 16 & 0xFF, lowerWordBaseMediaDecodeTime >>> 8 & 0xFF, lowerWordBaseMediaDecodeTime & 0xFF])); // the data offset specifies the number of bytes from the start of\n  // the containing moof to the first payload byte of the associated\n  // mdat\n\n  dataOffset = 32 + // tfhd\n  20 + // tfdt\n  8 + // traf header\n  16 + // mfhd\n  8 + // moof header\n  8; // mdat header\n  // audio tracks require less metadata\n\n  if (track.type === 'audio') {\n    trackFragmentRun = trun(track, dataOffset);\n    return box(types.traf, trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun);\n  } // video tracks should contain an independent and disposable samples\n  // box (sdtp)\n  // generate one and adjust offsets to match\n\n\n  sampleDependencyTable = sdtp(track);\n  trackFragmentRun = trun(track, sampleDependencyTable.length + dataOffset);\n  return box(types.traf, trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun, sampleDependencyTable);\n};\n/**\n * Generate a track box.\n * @param track {object} a track definition\n * @return {Uint8Array} the track box\n */\n\n\ntrak = function trak(track) {\n  track.duration = track.duration || 0xffffffff;\n  return box(types.trak, tkhd(track), mdia(track));\n};\n\ntrex = function trex(track) {\n  var result = new Uint8Array([0x00, // version 0\n  0x00, 0x00, 0x00, // flags\n  (track.id & 0xFF000000) >> 24, (track.id & 0xFF0000) >> 16, (track.id & 0xFF00) >> 8, track.id & 0xFF, // track_ID\n  0x00, 0x00, 0x00, 0x01, // default_sample_description_index\n  0x00, 0x00, 0x00, 0x00, // default_sample_duration\n  0x00, 0x00, 0x00, 0x00, // default_sample_size\n  0x00, 0x01, 0x00, 0x01 // default_sample_flags\n  ]); // the last two bytes of default_sample_flags is the sample\n  // degradation priority, a hint about the importance of this sample\n  // relative to others. Lower the degradation priority for all sample\n  // types other than video.\n\n  if (track.type !== 'video') {\n    result[result.length - 1] = 0x00;\n  }\n\n  return box(types.trex, result);\n};\n\n(function () {\n  var audioTrun, videoTrun, trunHeader; // This method assumes all samples are uniform. That is, if a\n  // duration is present for the first sample, it will be present for\n  // all subsequent samples.\n  // see ISO/IEC 14496-12:2012, Section 8.8.8.1\n\n  trunHeader = function trunHeader(samples, offset) {\n    var durationPresent = 0,\n        sizePresent = 0,\n        flagsPresent = 0,\n        compositionTimeOffset = 0; // trun flag constants\n\n    if (samples.length) {\n      if (samples[0].duration !== undefined) {\n        durationPresent = 0x1;\n      }\n\n      if (samples[0].size !== undefined) {\n        sizePresent = 0x2;\n      }\n\n      if (samples[0].flags !== undefined) {\n        flagsPresent = 0x4;\n      }\n\n      if (samples[0].compositionTimeOffset !== undefined) {\n        compositionTimeOffset = 0x8;\n      }\n    }\n\n    return [0x00, // version 0\n    0x00, durationPresent | sizePresent | flagsPresent | compositionTimeOffset, 0x01, // flags\n    (samples.length & 0xFF000000) >>> 24, (samples.length & 0xFF0000) >>> 16, (samples.length & 0xFF00) >>> 8, samples.length & 0xFF, // sample_count\n    (offset & 0xFF000000) >>> 24, (offset & 0xFF0000) >>> 16, (offset & 0xFF00) >>> 8, offset & 0xFF // data_offset\n    ];\n  };\n\n  videoTrun = function videoTrun(track, offset) {\n    var bytes, samples, sample, i;\n    samples = track.samples || [];\n    offset += 8 + 12 + 16 * samples.length;\n    bytes = trunHeader(samples, offset);\n\n    for (i = 0; i < samples.length; i++) {\n      sample = samples[i];\n      bytes = bytes.concat([(sample.duration & 0xFF000000) >>> 24, (sample.duration & 0xFF0000) >>> 16, (sample.duration & 0xFF00) >>> 8, sample.duration & 0xFF, // sample_duration\n      (sample.size & 0xFF000000) >>> 24, (sample.size & 0xFF0000) >>> 16, (sample.size & 0xFF00) >>> 8, sample.size & 0xFF, // sample_size\n      sample.flags.isLeading << 2 | sample.flags.dependsOn, sample.flags.isDependedOn << 6 | sample.flags.hasRedundancy << 4 | sample.flags.paddingValue << 1 | sample.flags.isNonSyncSample, sample.flags.degradationPriority & 0xF0 << 8, sample.flags.degradationPriority & 0x0F, // sample_flags\n      (sample.compositionTimeOffset & 0xFF000000) >>> 24, (sample.compositionTimeOffset & 0xFF0000) >>> 16, (sample.compositionTimeOffset & 0xFF00) >>> 8, sample.compositionTimeOffset & 0xFF // sample_composition_time_offset\n      ]);\n    }\n\n    return box(types.trun, new Uint8Array(bytes));\n  };\n\n  audioTrun = function audioTrun(track, offset) {\n    var bytes, samples, sample, i;\n    samples = track.samples || [];\n    offset += 8 + 12 + 8 * samples.length;\n    bytes = trunHeader(samples, offset);\n\n    for (i = 0; i < samples.length; i++) {\n      sample = samples[i];\n      bytes = bytes.concat([(sample.duration & 0xFF000000) >>> 24, (sample.duration & 0xFF0000) >>> 16, (sample.duration & 0xFF00) >>> 8, sample.duration & 0xFF, // sample_duration\n      (sample.size & 0xFF000000) >>> 24, (sample.size & 0xFF0000) >>> 16, (sample.size & 0xFF00) >>> 8, sample.size & 0xFF]); // sample_size\n    }\n\n    return box(types.trun, new Uint8Array(bytes));\n  };\n\n  trun = function trun(track, offset) {\n    if (track.type === 'audio') {\n      return audioTrun(track, offset);\n    }\n\n    return videoTrun(track, offset);\n  };\n})();\n\nmodule.exports = {\n  ftyp: ftyp,\n  mdat: mdat,\n  moof: moof,\n  moov: moov,\n  initSegment: function initSegment(tracks) {\n    var fileType = ftyp(),\n        movie = moov(tracks),\n        result;\n    result = new Uint8Array(fileType.byteLength + movie.byteLength);\n    result.set(fileType);\n    result.set(movie, fileType.byteLength);\n    return result;\n  }\n};","map":null,"metadata":{},"sourceType":"script"}